{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinkedIn Data Project\n",
    "\n",
    "Today's labor force scours the internet looking for employers who will provide a good work envirnment. While website reviews are helpful to understand a company's vibe and Google images captures an owner's desired feng shui, accurate employee data reveals more about a work setting than anthing else. \n",
    "\n",
    "This project shows employee data for 100 companies in the Tech field, Automotive industy, and food/beverage manufacturing respectively. It will look for job descriptions, duration with a company, and region the company is located, amoung other things. It will take this raw data and deliver it in an understandable Tableau dashboard. In so doing it will allow people to navigate their careers through informed decision making. \n",
    "\n",
    "The companies we will look at will be a sampling of their individual markets and the employee info gathered will be a sampling of the individual company. This will give us a normal distribution of how each company behaves. \n",
    "\n",
    "This can all be accomplished in three main steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step One: Gather Company URLs\n",
    "\n",
    "All three hundred companies we will look at were found at these websites: https://www.foodprocessing.com/top100/2020/, https://www.forbes.com/top-digital-companies/list/#tab:rank, and https://www.berylls.com/wp-content/uploads/2020/07/202007_BERYLLS_Study_Top_100_supplier-2019_EN.pdf. \n",
    "\n",
    "The data was taken and cleaned up on Google sheets to allow it to be used as lists in Python. Using these lists we used the Selemium package to gather the company URLs. \n",
    "\n",
    "The strategy used here is to get all the hrefs as we search each company and filter to get a unique list of urls with '/company/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "\n",
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(PATH)\n",
    "\n",
    "#log on to LinkedIn and access page\n",
    "driver.get(\"https://www.linkedin.com/company/tesla-motors/people/\")\n",
    "driver.find_element_by_xpath(\"/html[1]/body[1]/div[1]/main[1]/div[2]/div[1]/form[1]/div[1]/input[1]\").send_keys(\"********\")\n",
    "driver.find_element_by_xpath(\"/html[1]/body[1]/div[1]/main[1]/div[2]/div[1]/form[1]/div[2]/input[1]\").send_keys(\"********\")\n",
    "driver.find_element_by_xpath(\"//button[contains(text(),'Sign in')]\").click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "auto_href_list = []\n",
    "refined_auto = []\n",
    "auto_company_list = []\n",
    "final_auto = []\n",
    "substring = '/company/'\n",
    "substring2 = 'jobs'\n",
    "for company in tech_list:\n",
    "    driver.get('https://www.linkedin.com/company/tesla-motors/people/')\n",
    "    #Clicking on the search bar\n",
    "   \n",
    "    search = driver.find_element_by_xpath(\"//*[@id='global-nav-typeahead']/input\")\n",
    "    search.click()\n",
    "    time.sleep(1)\n",
    "    search.send_keys(company)\n",
    "    time.sleep(1)\n",
    "    driver.find_element_by_xpath('//*[@id=\"global-nav-typeahead\"]/input').send_keys(Keys.ENTER)\n",
    "    #driver.find_element_by_xpath(\"//div[@id='global-nav-typeahead']\").send_keys('hi')\n",
    "    time.sleep(1)\n",
    "    hrefs = driver.find_elements_by_xpath(\"//a[@href]\")\n",
    "    for href in hrefs:\n",
    "        auto_href_list.append(href.get_attribute(\"href\")) \n",
    "    for url in auto_href_list:\n",
    "        if substring in url and substring2 not in url:\n",
    "            auto_company_list.append(url)\n",
    "    for reference in auto_company_list:\n",
    "        if reference not in refined_auto:\n",
    "            refined_auto.append(reference)\n",
    "    for elem in refined_auto:\n",
    "        string_add = 'people/'\n",
    "        elem = elem + string_add\n",
    "        final_auto.append(elem)\n",
    "    auto_href_list.clear()\n",
    "    auto_company_list.clear()\n",
    "    refined_auto.clear()   \n",
    "auto_file = open('D:\\SpringBoard Capstone Practice\\\\techcompanyurlList.txt','w')\n",
    "for instance in final_auto:\n",
    "    auto_file.write(instance+'\\n')\n",
    "\n",
    "auto_file.close()           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Two: Retrieve Employee Profiles from Company URLs \n",
    "\n",
    "The strategy used here is to get the info by searching each company and getting the employee profiles in the hrefs with '/in/' in the url, while scrolling through the company employee page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCROLL_PAUSE_TIME = 3\n",
    "\n",
    "# Get scroll height\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "file = open(\"teslaprofiles.csv\", 'w')\n",
    "final_list = []\n",
    "# https://stackoverflow.com/questions/20986631/how-can-i-scroll-a-web-page-using-selenium-webdriver-in-python/27760083 (7/7/21) Cuong Tran\n",
    "while True:\n",
    "    # Scroll down to bottom\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Wait to load page\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    \n",
    "    substring = \"/in/\"\n",
    "   \n",
    "    profiles_list = []\n",
    "    links_list = []\n",
    "\n",
    "    hrefs = driver.find_elements_by_xpath(\"//a[@href]\")\n",
    "    for href in hrefs:\n",
    "        links_list.append(str(href.get_attribute(\"href\")))\n",
    "    for link in links_list:\n",
    "        if substring in link:\n",
    "            profiles_list.append(link)\n",
    "    for profile in profiles_list:\n",
    "        if profile not in final_list:\n",
    "            final_list.append(profile)\n",
    "            with open('file', 'w') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(profile)\n",
    "                print(profile)\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        file.close()\n",
    "        break\n",
    "    last_height = new_height\n",
    "    hrefs.clear()\n",
    "    profiles_list.clear()\n",
    "    print(len(final_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Three: Get Individual Employee data and send to CSV files\n",
    "\n",
    "The strategy here is to search through each employee profile and extract publicly available info using xpath. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.linkedin.com/in/michael-adams-b7053914b/')\n",
    "\n",
    "name = driver.find_element_by_xpath(\"//h1[contains(text(),'')]\").text\n",
    "employer = driver.find_element_by_xpath(\"//body/div[5]/div[3]/div[1]/div[1]/div[1]/div[1]/div[3]/div[1]/div[1]/main[1]/div[1]/section[1]/div[2]/div[2]/ul[1]/li[1]/a[1]/h2[1]/div[1]\").text\n",
    "job = driver.find_element_by_xpath(\"//body/div[5]/div[3]/div[1]/div[1]/div[1]/div[1]/div[3]/div[1]/div[1]/main[1]/div[1]/section[1]/div[2]/div[2]/div[1]/div[2]\").text\n",
    "\n",
    "exp = driver.find_element_by_xpath('/html/body/div[5]/div[3]/div/div/div/div/div[3]/div/div/main/div/div[5]/div[2]/span/div/section/div[1]/section/ul')\n",
    "\n",
    "area = driver.find_element_by_css_selector(\"#ember331 > div.pv-entity__summary-info.pv-entity__summary-info--background-section.mb2 > div > h4:nth-child(2) > span.pv-entity__bullet-item-v2\").text\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
